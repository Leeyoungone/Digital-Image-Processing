{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import os\n",
    "import seaborn as sns\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"image/classification\"))\n",
    "print(os.listdir(\"image/classification/train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SIZE = 256  #Resize images\n",
    "\n",
    "#Capture training data and labels into respective lists\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "\n",
    "for directory_path in glob.glob(\"image/classification/train/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.JPG\")):\n",
    "        # print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "\n",
    "#Convert lists to arrays        \n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture test/validation data and labels into respective lists\n",
    "\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "for directory_path in glob.glob(\"image/classification/validation/*\"):\n",
    "    fruit_label = directory_path.split(\"\\\\\")[-1]\n",
    "    print(fruit_label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.JPG\")):\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(fruit_label)\n",
    "\n",
    "#Convert lists to arrays                \n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode labels from text to integers.\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Normalize pixel values to between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "#One hot encode y values for neural network. \n",
    "# from keras.utils import to_categorical\n",
    "# y_train_one_hot = to_categorical(y_train)\n",
    "# y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model wothout classifier/fully connected layers\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "VGG_model.summary()  #Trainable parameters will be 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let us use features from convolutional network for RF\n",
    "feature_extractor=VGG_model.predict(x_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
    "\n",
    "X_for_training = features #This is our X input to RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_for_training, y_train) #For sklearn no one hot encoding\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature = VGG_model.predict(x_test)\n",
    "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now predict using the trained RF model. \n",
    "prediction = model.predict(X_test_features)\n",
    "#Inverse le transform to get original label back. \n",
    "prediction = le.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print overall accuracy\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(test_labels, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix - verify accuracy of each class\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(test_labels, prediction)\n",
    "#print(cm)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check results on a few select images\n",
    "n=np.random.randint(0, x_test.shape[0])\n",
    "img = x_test[n]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "input_img_feature=VGG_model.predict(input_img)\n",
    "input_img_features=input_img_feature.reshape(input_img_feature.shape[0], -1)\n",
    "prediction = model.predict(input_img_features)[0] \n",
    "prediction = le.inverse_transform([prediction])  #Reverse the label encoder to original name\n",
    "print(\"The prediction for this image is: \", prediction)\n",
    "print(\"The actual label for this image is: \", test_labels[n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
